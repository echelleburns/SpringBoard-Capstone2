{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model - Initial Runs\n",
    "\n",
    "This notebook goes over how to create a data generator that reads in a section of a dataset and trains the model sequentially. It also goes through several different types of models. \n",
    "\n",
    "TensorFlow wasn't loading properly on my Windows computer, so I followed this link to create a new environment to run tensorflow things: https://medium.com/@mengjiunchiou/how-to-set-keras-with-tensorflow-with-conda-virtual-environment-on-ubuntu-5d56d22e3dc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\echel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\echel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\echel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\echel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\echel\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from skimage import io, filters, measure\n",
    "from scipy import ndimage\n",
    "from keras.models import Sequential\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image # for conversion to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data have been pre-processed already. The raw images were converted\n",
    "# to grayscale and were split into 25 smaller images. Labeled images\n",
    "# were created from the original images and are a series of 0 (no \n",
    "# person) and 255 (a person). The labeled images were also split\n",
    "# into 25 pieces so that they would match the original images. \n",
    "\n",
    "# Find location of image files and labeled images\n",
    "data = glob('../data/raw/resized/with_people/splits/*hsv*.png')\n",
    "labels = glob('../data/processed/dots/with_people/splits/*.png')\n",
    "\n",
    "# Split into the training and testing data\n",
    "train_X, test_X = train_test_split(data, test_size=0.25, random_state=33)\n",
    "train_Y, test_Y = train_test_split(labels, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to make a data generator for the model\n",
    "def gather_images(images, labels, batch_size=10): \n",
    "    \"\"\" Takes the original and labeled images, combines them into np \"\"\"\n",
    "    \"\"\" arrays, and passes to model\"\"\"\n",
    "    while 1: \n",
    "        for offset in range(0, len(images), batch_size): \n",
    "            X = [] # empty list for training data\n",
    "            Y = [] # empty list for labels \n",
    "            for img in images[offset:offset+batch_size]: # for each image in the list\n",
    "                img_temp = cv2.imread(img)\n",
    "                #img_temp = Image.open(img).convert('LA')\n",
    "                #img_temp = cv2.cvtColor(img_temp, cv2.COLOR_BGR2HSV)\n",
    "                img_flatten = np.array(img_temp) # create np array\n",
    "                X.append(img_flatten) # and add to list for X\n",
    "            for lab in labels[offset:offset+batch_size]: # for each label in the list\n",
    "                label_temp = io.imread(lab, as_gray=True)\n",
    "                labels_temp = measure.label(label_temp)\n",
    "                label_flatten = labels_temp.max() # create np array\n",
    "                Y.append(label_flatten) # and add to list for y\n",
    "            yield (np.array(X), np.array(Y).reshape(len(Y),1)) # yield X and y for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1: Full Images - GrayScale\n",
    "This uses full size images that have people in them, converted to grayscale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================]39/39 [==============================] - 74s 2s/step - loss: 1848.7436 - mean_squared_error: 1848.7436 - mean_absolute_error: 21.0740 - acc: 0.0333\n",
      "\n",
      "Epoch 2/10\n",
      "39/39 [==============================]39/39 [==============================] - 69s 2s/step - loss: 28.3969 - mean_squared_error: 28.3969 - mean_absolute_error: 3.9576 - acc: 0.1128\n",
      "\n",
      "Epoch 3/10\n",
      "39/39 [==============================]39/39 [==============================] - 71s 2s/step - loss: 20.1725 - mean_squared_error: 20.1725 - mean_absolute_error: 3.0874 - acc: 0.1077\n",
      "\n",
      "Epoch 4/10\n",
      "39/39 [==============================]39/39 [==============================] - 70s 2s/step - loss: 16.9439 - mean_squared_error: 16.9439 - mean_absolute_error: 2.7732 - acc: 0.1590\n",
      "\n",
      "Epoch 5/10\n",
      "39/39 [==============================]39/39 [==============================] - 72s 2s/step - loss: 15.1568 - mean_squared_error: 15.1568 - mean_absolute_error: 2.5791 - acc: 0.1615\n",
      "\n",
      "Epoch 6/10\n",
      "39/39 [==============================]39/39 [==============================] - 71s 2s/step - loss: 15.1216 - mean_squared_error: 15.1216 - mean_absolute_error: 2.5592 - acc: 0.1744\n",
      "\n",
      "Epoch 7/10\n",
      "39/39 [==============================]39/39 [==============================] - 73s 2s/step - loss: 14.8291 - mean_squared_error: 14.8291 - mean_absolute_error: 2.5504 - acc: 0.1564\n",
      "\n",
      "Epoch 8/10\n",
      "39/39 [==============================]39/39 [==============================] - 71s 2s/step - loss: 14.3345 - mean_squared_error: 14.3345 - mean_absolute_error: 2.5083 - acc: 0.1462\n",
      "\n",
      "Epoch 9/10\n",
      "39/39 [==============================]39/39 [==============================] - 77s 2s/step - loss: 13.4340 - mean_squared_error: 13.4340 - mean_absolute_error: 2.3725 - acc: 0.1872\n",
      "\n",
      "Epoch 10/10\n",
      "39/39 [==============================]39/39 [==============================] - 77s 2s/step - loss: 13.2854 - mean_squared_error: 13.2854 - mean_absolute_error: 2.4094 - acc: 0.1667\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f259d8bfd0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (2,2), padding=\"same\",input_shape=(540, 960, 2), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'accuracy'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.4597096]\n",
      " [4.0453725]\n",
      " [2.5865219]\n",
      " [1.876172 ]\n",
      " [2.7817848]\n",
      " [4.3727183]\n",
      " [3.9000027]\n",
      " [2.5050535]\n",
      " [3.3840609]\n",
      " [3.5734978]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7]\n",
      " [5]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [9]\n",
      " [3]\n",
      " [2]\n",
      " [3]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2: Full Images - HSV\n",
    "This uses full size images that have people in them, converted to HSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================]39/39 [==============================] - 87s 2s/step - loss: 2378.7755 - mean_squared_error: 2378.7755 - mean_absolute_error: 24.0337 - acc: 0.0385\n",
      "\n",
      "Epoch 2/10\n",
      "39/39 [==============================]39/39 [==============================] - 83s 2s/step - loss: 15.1942 - mean_squared_error: 15.1942 - mean_absolute_error: 2.4477 - acc: 0.1872\n",
      "\n",
      "Epoch 3/10\n",
      "39/39 [==============================]39/39 [==============================] - 84s 2s/step - loss: 11.7206 - mean_squared_error: 11.7206 - mean_absolute_error: 2.2168 - acc: 0.1897\n",
      "\n",
      "Epoch 4/10\n",
      "39/39 [==============================]39/39 [==============================] - 86s 2s/step - loss: 10.5186 - mean_squared_error: 10.5186 - mean_absolute_error: 2.1461 - acc: 0.2333\n",
      "\n",
      "Epoch 5/10\n",
      "39/39 [==============================]39/39 [==============================] - 90s 2s/step - loss: 7.3852 - mean_squared_error: 7.3852 - mean_absolute_error: 1.7826 - acc: 0.2410\n",
      "\n",
      "Epoch 6/10\n",
      "39/39 [==============================]39/39 [==============================] - 82s 2s/step - loss: 5.5666 - mean_squared_error: 5.5666 - mean_absolute_error: 1.5621 - acc: 0.2718\n",
      "\n",
      "Epoch 7/10\n",
      "39/39 [==============================]39/39 [==============================] - 94s 2s/step - loss: 4.4254 - mean_squared_error: 4.4254 - mean_absolute_error: 1.4214 - acc: 0.2974\n",
      "\n",
      "Epoch 8/10\n",
      "39/39 [==============================]39/39 [==============================] - 83s 2s/step - loss: 3.8750 - mean_squared_error: 3.8750 - mean_absolute_error: 1.3513 - acc: 0.3051\n",
      "\n",
      "Epoch 9/10\n",
      "39/39 [==============================]39/39 [==============================] - 84s 2s/step - loss: 3.3686 - mean_squared_error: 3.3686 - mean_absolute_error: 1.2665 - acc: 0.2974\n",
      "\n",
      "Epoch 10/10\n",
      "39/39 [==============================]39/39 [==============================] - 86s 2s/step - loss: 4.5964 - mean_squared_error: 4.5964 - mean_absolute_error: 1.3662 - acc: 0.3333\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f25ad63fd0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (2,2), padding=\"same\",input_shape=(540, 960, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'accuracy'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0930457]\n",
      " [2.5246828]\n",
      " [1.4346604]\n",
      " [1.3098843]\n",
      " [1.7063771]\n",
      " [1.902762 ]\n",
      " [3.913823 ]\n",
      " [1.0183108]\n",
      " [1.3632728]\n",
      " [3.1236968]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7]\n",
      " [5]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [9]\n",
      " [3]\n",
      " [2]\n",
      " [3]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 3: Full Images - No Color Change\n",
    "This uses full size images that have people in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================]39/39 [==============================] - 85s 2s/step - loss: 1208.7269 - mean_squared_error: 1208.7269 - mean_absolute_error: 17.7038 - acc: 0.0231\n",
      "\n",
      "Epoch 2/10\n",
      "39/39 [==============================]39/39 [==============================] - 83s 2s/step - loss: 19.3600 - mean_squared_error: 19.3600 - mean_absolute_error: 3.0794 - acc: 0.1308\n",
      "\n",
      "Epoch 3/10\n",
      "39/39 [==============================]39/39 [==============================] - 80s 2s/step - loss: 14.3952 - mean_squared_error: 14.3952 - mean_absolute_error: 2.6225 - acc: 0.1462\n",
      "\n",
      "Epoch 4/10\n",
      "39/39 [==============================]39/39 [==============================] - 80s 2s/step - loss: 13.8770 - mean_squared_error: 13.8770 - mean_absolute_error: 2.4535 - acc: 0.1949\n",
      "\n",
      "Epoch 5/10\n",
      "39/39 [==============================]39/39 [==============================] - 81s 2s/step - loss: 11.1326 - mean_squared_error: 11.1326 - mean_absolute_error: 2.1599 - acc: 0.1923\n",
      "\n",
      "Epoch 6/10\n",
      "39/39 [==============================]39/39 [==============================] - 83s 2s/step - loss: 7.7102 - mean_squared_error: 7.7102 - mean_absolute_error: 1.9524 - acc: 0.2077\n",
      "\n",
      "Epoch 7/10\n",
      "39/39 [==============================]39/39 [==============================] - 81s 2s/step - loss: 6.7028 - mean_squared_error: 6.7028 - mean_absolute_error: 1.7195 - acc: 0.2436\n",
      "\n",
      "Epoch 8/10\n",
      "39/39 [==============================]39/39 [==============================] - 82s 2s/step - loss: 5.4880 - mean_squared_error: 5.4880 - mean_absolute_error: 1.6353 - acc: 0.2564\n",
      "\n",
      "Epoch 9/10\n",
      "39/39 [==============================]39/39 [==============================] - 83s 2s/step - loss: 5.0590 - mean_squared_error: 5.0590 - mean_absolute_error: 1.5240 - acc: 0.2923\n",
      "\n",
      "Epoch 10/10\n",
      "39/39 [==============================]39/39 [==============================] - 81s 2s/step - loss: 4.9470 - mean_squared_error: 4.9470 - mean_absolute_error: 1.4971 - acc: 0.3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f25c490240>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (2,2), padding=\"same\",input_shape=(540, 960, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'accuracy'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.3958495 ]\n",
      " [8.321123  ]\n",
      " [2.3532782 ]\n",
      " [1.035324  ]\n",
      " [0.70101446]\n",
      " [2.332126  ]\n",
      " [4.5625787 ]\n",
      " [0.87305564]\n",
      " [1.6255327 ]\n",
      " [2.5387604 ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7]\n",
      " [5]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [9]\n",
      " [3]\n",
      " [2]\n",
      " [3]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 4: Split Images - Grayscale\n",
    "This uses split images (from full images with people in them) that have been converted to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "976/976 [==============================]976/976 [==============================] - 309s 316ms/step - loss: 3.6022 - mean_squared_error: 3.6022 - mean_absolute_error: 0.4892 - acc: 0.8026\n",
      "\n",
      "Epoch 2/10\n",
      "976/976 [==============================]976/976 [==============================] - 105s 107ms/step - loss: 0.2864 - mean_squared_error: 0.2864 - mean_absolute_error: 0.2316 - acc: 0.8929\n",
      "\n",
      "Epoch 3/10\n",
      "976/976 [==============================]976/976 [==============================] - 113s 116ms/step - loss: 0.2791 - mean_squared_error: 0.2791 - mean_absolute_error: 0.2264 - acc: 0.8944\n",
      "\n",
      "Epoch 4/10\n",
      "976/976 [==============================]976/976 [==============================] - 105s 108ms/step - loss: 0.2707 - mean_squared_error: 0.2707 - mean_absolute_error: 0.2226 - acc: 0.8972\n",
      "\n",
      "Epoch 5/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 105ms/step - loss: 0.2707 - mean_squared_error: 0.2707 - mean_absolute_error: 0.2240 - acc: 0.8969\n",
      "\n",
      "Epoch 6/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 103ms/step - loss: 0.2708 - mean_squared_error: 0.2708 - mean_absolute_error: 0.2266 - acc: 0.8995\n",
      "\n",
      "Epoch 7/10\n",
      "976/976 [==============================]976/976 [==============================] - 100s 102ms/step - loss: 0.2708 - mean_squared_error: 0.2708 - mean_absolute_error: 0.2264 - acc: 0.8964\n",
      "\n",
      "Epoch 8/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 104ms/step - loss: 0.2647 - mean_squared_error: 0.2647 - mean_absolute_error: 0.2256 - acc: 0.9007\n",
      "\n",
      "Epoch 9/10\n",
      "976/976 [==============================]976/976 [==============================] - 100s 103ms/step - loss: 0.2709 - mean_squared_error: 0.2709 - mean_absolute_error: 0.2239 - acc: 0.8993\n",
      "\n",
      "Epoch 10/10\n",
      "976/976 [==============================]976/976 [==============================] - 99s 101ms/step - loss: 0.2824 - mean_squared_error: 0.2824 - mean_absolute_error: 0.2380 - acc: 0.8998\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f23f893128>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (2,2), padding=\"same\",input_shape=(108, 192, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'accuracy'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1062379 ]\n",
      " [0.12491779]\n",
      " [0.16854063]\n",
      " [0.10197994]\n",
      " [0.10313762]\n",
      " [0.11242331]\n",
      " [0.23321387]\n",
      " [0.10273636]\n",
      " [0.10166924]\n",
      " [0.10310157]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 5: Split Images - HSV\n",
    "This uses split images (from full images with people in them) that have been converted to hsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "325/325 [==============================]325/325 [==============================] - 195s 601ms/step - loss: 1.8116 - mean_squared_error: 1.8116 - mean_absolute_error: 0.4146\n",
      "\n",
      "Epoch 2/30\n",
      "325/325 [==============================]325/325 [==============================] - 195s 599ms/step - loss: 0.2958 - mean_squared_error: 0.2958 - mean_absolute_error: 0.2440\n",
      "\n",
      "Epoch 3/30\n",
      "325/325 [==============================]325/325 [==============================] - 194s 598ms/step - loss: 0.2921 - mean_squared_error: 0.2921 - mean_absolute_error: 0.2450\n",
      "\n",
      "Epoch 4/30\n",
      "325/325 [==============================]325/325 [==============================] - 198s 610ms/step - loss: 0.2882 - mean_squared_error: 0.2882 - mean_absolute_error: 0.2465\n",
      "\n",
      "Epoch 5/30\n",
      "325/325 [==============================]325/325 [==============================] - 193s 593ms/step - loss: 0.2833 - mean_squared_error: 0.2833 - mean_absolute_error: 0.2473\n",
      "\n",
      "Epoch 6/30\n",
      "325/325 [==============================]325/325 [==============================] - 194s 598ms/step - loss: 0.2788 - mean_squared_error: 0.2788 - mean_absolute_error: 0.2391\n",
      "\n",
      "Epoch 7/30\n",
      "325/325 [==============================]325/325 [==============================] - 196s 605ms/step - loss: 0.2744 - mean_squared_error: 0.2744 - mean_absolute_error: 0.2433\n",
      "\n",
      "Epoch 8/30\n",
      "325/325 [==============================]325/325 [==============================] - 200s 615ms/step - loss: 0.2642 - mean_squared_error: 0.2642 - mean_absolute_error: 0.2379\n",
      "\n",
      "Epoch 9/30\n",
      "325/325 [==============================]325/325 [==============================] - 196s 602ms/step - loss: 0.2676 - mean_squared_error: 0.2676 - mean_absolute_error: 0.2380\n",
      "\n",
      "Epoch 10/30\n",
      "325/325 [==============================]325/325 [==============================] - 198s 608ms/step - loss: 0.2708 - mean_squared_error: 0.2708 - mean_absolute_error: 0.2450\n",
      "\n",
      "Epoch 11/30\n",
      "325/325 [==============================]325/325 [==============================] - 193s 594ms/step - loss: 0.2829 - mean_squared_error: 0.2829 - mean_absolute_error: 0.2475\n",
      "\n",
      "Epoch 12/30\n",
      "325/325 [==============================]325/325 [==============================] - 186s 571ms/step - loss: 0.2763 - mean_squared_error: 0.2763 - mean_absolute_error: 0.2448\n",
      "\n",
      "Epoch 13/30\n",
      "325/325 [==============================]325/325 [==============================] - 190s 585ms/step - loss: 0.2730 - mean_squared_error: 0.2730 - mean_absolute_error: 0.2502\n",
      "\n",
      "Epoch 14/30\n",
      "325/325 [==============================]325/325 [==============================] - 192s 590ms/step - loss: 0.2758 - mean_squared_error: 0.2758 - mean_absolute_error: 0.2362\n",
      "\n",
      "Epoch 15/30\n",
      "325/325 [==============================]325/325 [==============================] - 189s 582ms/step - loss: 0.2968 - mean_squared_error: 0.2968 - mean_absolute_error: 0.2580\n",
      "\n",
      "Epoch 16/30\n",
      "325/325 [==============================]325/325 [==============================] - 189s 580ms/step - loss: 0.2879 - mean_squared_error: 0.2879 - mean_absolute_error: 0.2570\n",
      "\n",
      "Epoch 17/30\n",
      "325/325 [==============================]325/325 [==============================] - 196s 603ms/step - loss: 0.2701 - mean_squared_error: 0.2701 - mean_absolute_error: 0.2388\n",
      "\n",
      "Epoch 18/30\n",
      "325/325 [==============================]325/325 [==============================] - 187s 574ms/step - loss: 0.2591 - mean_squared_error: 0.2591 - mean_absolute_error: 0.2251\n",
      "\n",
      "Epoch 19/30\n",
      "325/325 [==============================]325/325 [==============================] - 184s 565ms/step - loss: 0.2193 - mean_squared_error: 0.2193 - mean_absolute_error: 0.1962\n",
      "\n",
      "Epoch 20/30\n",
      "325/325 [==============================]325/325 [==============================] - 181s 556ms/step - loss: 0.2003 - mean_squared_error: 0.2003 - mean_absolute_error: 0.1893\n",
      "\n",
      "Epoch 21/30\n",
      "325/325 [==============================]325/325 [==============================] - 180s 555ms/step - loss: 0.2076 - mean_squared_error: 0.2076 - mean_absolute_error: 0.1891\n",
      "\n",
      "Epoch 22/30\n",
      "325/325 [==============================]325/325 [==============================] - 190s 586ms/step - loss: 0.2065 - mean_squared_error: 0.2065 - mean_absolute_error: 0.1826\n",
      "\n",
      "Epoch 23/30\n",
      "325/325 [==============================]325/325 [==============================] - 186s 572ms/step - loss: 0.1953 - mean_squared_error: 0.1953 - mean_absolute_error: 0.1795\n",
      "\n",
      "Epoch 24/30\n",
      "325/325 [==============================]325/325 [==============================] - 189s 581ms/step - loss: 0.1913 - mean_squared_error: 0.1913 - mean_absolute_error: 0.1765\n",
      "\n",
      "Epoch 25/30\n",
      "325/325 [==============================]325/325 [==============================] - 192s 590ms/step - loss: 0.2040 - mean_squared_error: 0.2040 - mean_absolute_error: 0.1849\n",
      "\n",
      "Epoch 26/30\n",
      "325/325 [==============================]325/325 [==============================] - 192s 590ms/step - loss: 0.1913 - mean_squared_error: 0.1913 - mean_absolute_error: 0.1803\n",
      "\n",
      "Epoch 27/30\n",
      "325/325 [==============================]325/325 [==============================] - 192s 592ms/step - loss: 0.1786 - mean_squared_error: 0.1786 - mean_absolute_error: 0.1697\n",
      "\n",
      "Epoch 28/30\n",
      "325/325 [==============================]325/325 [==============================] - 196s 602ms/step - loss: 0.1791 - mean_squared_error: 0.1791 - mean_absolute_error: 0.1652\n",
      "\n",
      "Epoch 29/30\n",
      "325/325 [==============================]325/325 [==============================] - 193s 594ms/step - loss: 0.1709 - mean_squared_error: 0.1709 - mean_absolute_error: 0.1620\n",
      "\n",
      "Epoch 30/30\n",
      "325/325 [==============================]325/325 [==============================] - 197s 606ms/step - loss: 0.1502 - mean_squared_error: 0.1502 - mean_absolute_error: 0.1520\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f283893d30>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 30\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (5,5), padding=\"same\",input_shape=(108, 192, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(3,3)),\n",
    "  tf.keras.layers.Conv2D(16, (5,5), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(3,3)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1, activation='linear'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "325/325 [==============================]325/325 [==============================] - 321s 987ms/step - loss: 18.1632 - mean_squared_error: 18.1632 - mean_absolute_error: 0.8407\n",
      "\n",
      "Epoch 2/30\n",
      "325/325 [==============================]325/325 [==============================] - 294s 904ms/step - loss: 0.2967 - mean_squared_error: 0.2967 - mean_absolute_error: 0.2464\n",
      "\n",
      "Epoch 3/30\n",
      "325/325 [==============================]325/325 [==============================] - 301s 926ms/step - loss: 0.2871 - mean_squared_error: 0.2871 - mean_absolute_error: 0.2405\n",
      "\n",
      "Epoch 4/30\n",
      "325/325 [==============================]325/325 [==============================] - 293s 900ms/step - loss: 0.2797 - mean_squared_error: 0.2797 - mean_absolute_error: 0.2309\n",
      "\n",
      "Epoch 5/30\n",
      "325/325 [==============================]325/325 [==============================] - 291s 895ms/step - loss: 0.2662 - mean_squared_error: 0.2662 - mean_absolute_error: 0.2220\n",
      "\n",
      "Epoch 6/30\n",
      "325/325 [==============================]325/325 [==============================] - 293s 901ms/step - loss: 0.2592 - mean_squared_error: 0.2592 - mean_absolute_error: 0.2152\n",
      "\n",
      "Epoch 7/30\n",
      "325/325 [==============================]325/325 [==============================] - 295s 907ms/step - loss: 0.2478 - mean_squared_error: 0.2478 - mean_absolute_error: 0.2098\n",
      "\n",
      "Epoch 8/30\n",
      "325/325 [==============================]325/325 [==============================] - 303s 933ms/step - loss: 0.2356 - mean_squared_error: 0.2356 - mean_absolute_error: 0.2007\n",
      "\n",
      "Epoch 9/30\n",
      "325/325 [==============================]325/325 [==============================] - 291s 894ms/step - loss: 0.2290 - mean_squared_error: 0.2290 - mean_absolute_error: 0.2027\n",
      "\n",
      "Epoch 10/30\n",
      "325/325 [==============================]325/325 [==============================] - 302s 929ms/step - loss: 0.2144 - mean_squared_error: 0.2144 - mean_absolute_error: 0.1923\n",
      "\n",
      "Epoch 11/30\n",
      "325/325 [==============================]325/325 [==============================] - 296s 911ms/step - loss: 0.1996 - mean_squared_error: 0.1996 - mean_absolute_error: 0.1895\n",
      "\n",
      "Epoch 12/30\n",
      "325/325 [==============================]325/325 [==============================] - 299s 919ms/step - loss: 0.2069 - mean_squared_error: 0.2069 - mean_absolute_error: 0.1884\n",
      "\n",
      "Epoch 13/30\n",
      "325/325 [==============================]325/325 [==============================] - 300s 922ms/step - loss: 0.1997 - mean_squared_error: 0.1997 - mean_absolute_error: 0.1856\n",
      "\n",
      "Epoch 14/30\n",
      "325/325 [==============================]325/325 [==============================] - 299s 921ms/step - loss: 0.1910 - mean_squared_error: 0.1910 - mean_absolute_error: 0.1818\n",
      "\n",
      "Epoch 15/30\n",
      "325/325 [==============================]325/325 [==============================] - 291s 895ms/step - loss: 0.1823 - mean_squared_error: 0.1823 - mean_absolute_error: 0.1804\n",
      "\n",
      "Epoch 16/30\n",
      "325/325 [==============================]325/325 [==============================] - 288s 888ms/step - loss: 0.1570 - mean_squared_error: 0.1570 - mean_absolute_error: 0.1698\n",
      "\n",
      "Epoch 17/30\n",
      "325/325 [==============================]325/325 [==============================] - 302s 928ms/step - loss: 0.1593 - mean_squared_error: 0.1593 - mean_absolute_error: 0.1743\n",
      "\n",
      "Epoch 18/30\n",
      "325/325 [==============================]325/325 [==============================] - 294s 905ms/step - loss: 0.1573 - mean_squared_error: 0.1573 - mean_absolute_error: 0.1648\n",
      "\n",
      "Epoch 19/30\n",
      "325/325 [==============================]325/325 [==============================] - 288s 888ms/step - loss: 0.2060 - mean_squared_error: 0.2060 - mean_absolute_error: 0.1896\n",
      "\n",
      "Epoch 20/30\n",
      "325/325 [==============================]325/325 [==============================] - 290s 892ms/step - loss: 0.1758 - mean_squared_error: 0.1758 - mean_absolute_error: 0.1800\n",
      "\n",
      "Epoch 21/30\n",
      "325/325 [==============================]325/325 [==============================] - 283s 869ms/step - loss: 0.1992 - mean_squared_error: 0.1992 - mean_absolute_error: 0.1903\n",
      "\n",
      "Epoch 22/30\n",
      "325/325 [==============================]325/325 [==============================] - 282s 867ms/step - loss: 0.1855 - mean_squared_error: 0.1855 - mean_absolute_error: 0.1885\n",
      "\n",
      "Epoch 23/30\n",
      "325/325 [==============================]325/325 [==============================] - 292s 899ms/step - loss: 0.1603 - mean_squared_error: 0.1603 - mean_absolute_error: 0.1735\n",
      "\n",
      "Epoch 24/30\n",
      "325/325 [==============================]325/325 [==============================] - 294s 903ms/step - loss: 0.1632 - mean_squared_error: 0.1632 - mean_absolute_error: 0.1753\n",
      "\n",
      "Epoch 25/30\n",
      "325/325 [==============================]325/325 [==============================] - 295s 907ms/step - loss: 0.1701 - mean_squared_error: 0.1701 - mean_absolute_error: 0.1796\n",
      "\n",
      "Epoch 26/30\n",
      "325/325 [==============================]325/325 [==============================] - 298s 916ms/step - loss: 0.2903 - mean_squared_error: 0.2903 - mean_absolute_error: 0.2350\n",
      "\n",
      "Epoch 27/30\n",
      "325/325 [==============================]325/325 [==============================] - 311s 956ms/step - loss: 0.2557 - mean_squared_error: 0.2557 - mean_absolute_error: 0.2288\n",
      "\n",
      "Epoch 28/30\n",
      "240/325 [=====================>........]240/325 [=====================>........] - ETA: 1:26 - loss: 0.2428 - mean_squared_error: 0.2428 - mean_absolute_error: 0.2099"
     ]
    }
   ],
   "source": [
    "batch_size = 30\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (7,7), padding=\"same\",input_shape=(108, 192, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(3,3)),\n",
    "  tf.keras.layers.Conv2D(16, (5,5), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(3,3)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1, activation='linear'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06639786]\n",
      " [0.597787  ]\n",
      " [0.05902122]\n",
      " [0.04196331]\n",
      " [0.04343889]\n",
      " [0.25613928]\n",
      " [0.04196331]\n",
      " [0.12044369]\n",
      " [0.04196331]\n",
      " [0.04298855]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 6: Split Images - No Color Change\n",
    "This uses split images (from full images with people in them). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 104ms/step - loss: 1.9541 - mean_squared_error: 1.9541 - mean_absolute_error: 0.4151 - acc: 0.8239\n",
      "\n",
      "Epoch 2/10\n",
      "976/976 [==============================]976/976 [==============================] - 97s 100ms/step - loss: 0.2725 - mean_squared_error: 0.2725 - mean_absolute_error: 0.2224 - acc: 0.8905\n",
      "\n",
      "Epoch 3/10\n",
      "976/976 [==============================]976/976 [==============================] - 105s 107ms/step - loss: 0.2613 - mean_squared_error: 0.2613 - mean_absolute_error: 0.2167 - acc: 0.8943\n",
      "\n",
      "Epoch 4/10\n",
      "976/976 [==============================]976/976 [==============================] - 104s 107ms/step - loss: 0.2624 - mean_squared_error: 0.2624 - mean_absolute_error: 0.2197 - acc: 0.8954\n",
      "\n",
      "Epoch 5/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 105ms/step - loss: 0.2544 - mean_squared_error: 0.2544 - mean_absolute_error: 0.2163 - acc: 0.8962\n",
      "\n",
      "Epoch 6/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 105ms/step - loss: 0.2494 - mean_squared_error: 0.2494 - mean_absolute_error: 0.2193 - acc: 0.8978\n",
      "\n",
      "Epoch 7/10\n",
      "976/976 [==============================]976/976 [==============================] - 103s 105ms/step - loss: 0.2523 - mean_squared_error: 0.2523 - mean_absolute_error: 0.2147 - acc: 0.8985\n",
      "\n",
      "Epoch 8/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 104ms/step - loss: 0.2659 - mean_squared_error: 0.2659 - mean_absolute_error: 0.2335 - acc: 0.8972\n",
      "\n",
      "Epoch 9/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 105ms/step - loss: 0.2607 - mean_squared_error: 0.2607 - mean_absolute_error: 0.2244 - acc: 0.9012\n",
      "\n",
      "Epoch 10/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 103ms/step - loss: 0.2926 - mean_squared_error: 0.2926 - mean_absolute_error: 0.2544 - acc: 0.9014\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f25bac0eb8>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (2,2), padding=\"same\",input_shape=(108, 192, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'accuracy'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13789415]\n",
      " [0.25354084]\n",
      " [0.13789415]\n",
      " [0.13789415]\n",
      " [0.13789415]\n",
      " [0.1382464 ]\n",
      " [0.19708386]\n",
      " [0.1383607 ]\n",
      " [0.13789415]\n",
      " [0.13789415]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_notebook",
   "language": "python",
   "name": "tensor_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
