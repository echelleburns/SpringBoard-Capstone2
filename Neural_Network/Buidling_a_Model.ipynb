{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Image Generator\n",
    "\n",
    "This notebook goes over how to create a data generator that reads in a section of a dataset and trains the model sequentially. \n",
    "\n",
    "TensorFlow wasn't loading properly on my Windows computer, so I followed this link to create a new environment to run tensorflow things: https://medium.com/@mengjiunchiou/how-to-set-keras-with-tensorflow-with-conda-virtual-environment-on-ubuntu-5d56d22e3dc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from skimage import io, filters, measure\n",
    "from scipy import ndimage\n",
    "from keras.models import Sequential\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image # for conversion to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data have been pre-processed already. The raw images were converted\n",
    "# to grayscale and were split into 25 smaller images. Labeled images\n",
    "# were created from the original images and are a series of 0 (no \n",
    "# person) and 255 (a person). The labeled images were also split\n",
    "# into 25 pieces so that they would match the original images. \n",
    "\n",
    "# Find location of image files and labeled images\n",
    "data = glob('data/raw/resized/with_people/splits/*full_color*.png')\n",
    "labels = glob('data/processed/dots/with_people/splits/*.png')\n",
    "\n",
    "# Split into the training and testing data\n",
    "train_X, test_X = train_test_split(data, test_size=0.25, random_state=33)\n",
    "train_Y, test_Y = train_test_split(labels, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to make a data generator for the model\n",
    "def gather_images(images, labels, batch_size=10): \n",
    "    \"\"\" Takes the original and labeled images, combines them into np \"\"\"\n",
    "    \"\"\" arrays, and passes to model\"\"\"\n",
    "    while 1: \n",
    "        for offset in range(0, len(images), batch_size): \n",
    "            X = [] # empty list for training data\n",
    "            Y = [] # empty list for labels \n",
    "            for img in images[offset:offset+batch_size]: # for each image in the list\n",
    "                img_temp = cv2.imread(img)\n",
    "                #img_temp = Image.open(img).convert('LA')\n",
    "                #img_temp = cv2.cvtColor(img_temp, cv2.COLOR_BGR2HSV)\n",
    "                img_flatten = np.array(img_temp) # create np array\n",
    "                X.append(img_flatten) # and add to list for X\n",
    "            for lab in labels[offset:offset+batch_size]: # for each label in the list\n",
    "                label_temp = io.imread(lab, as_gray=True)\n",
    "                labels_temp = measure.label(label_temp)\n",
    "                label_flatten = labels_temp.max() # create np array\n",
    "                Y.append(label_flatten) # and add to list for y\n",
    "            yield (np.array(X), np.array(Y).reshape(len(Y),1)) # yield X and y for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1: Full Images - GrayScale\n",
    "This uses full size images that have people in them, converted to grayscale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================]39/39 [==============================] - 74s 2s/step - loss: 1848.7436 - mean_squared_error: 1848.7436 - mean_absolute_error: 21.0740 - acc: 0.0333\n",
      "\n",
      "Epoch 2/10\n",
      "39/39 [==============================]39/39 [==============================] - 69s 2s/step - loss: 28.3969 - mean_squared_error: 28.3969 - mean_absolute_error: 3.9576 - acc: 0.1128\n",
      "\n",
      "Epoch 3/10\n",
      "39/39 [==============================]39/39 [==============================] - 71s 2s/step - loss: 20.1725 - mean_squared_error: 20.1725 - mean_absolute_error: 3.0874 - acc: 0.1077\n",
      "\n",
      "Epoch 4/10\n",
      "39/39 [==============================]39/39 [==============================] - 70s 2s/step - loss: 16.9439 - mean_squared_error: 16.9439 - mean_absolute_error: 2.7732 - acc: 0.1590\n",
      "\n",
      "Epoch 5/10\n",
      "39/39 [==============================]39/39 [==============================] - 72s 2s/step - loss: 15.1568 - mean_squared_error: 15.1568 - mean_absolute_error: 2.5791 - acc: 0.1615\n",
      "\n",
      "Epoch 6/10\n",
      "39/39 [==============================]39/39 [==============================] - 71s 2s/step - loss: 15.1216 - mean_squared_error: 15.1216 - mean_absolute_error: 2.5592 - acc: 0.1744\n",
      "\n",
      "Epoch 7/10\n",
      "39/39 [==============================]39/39 [==============================] - 73s 2s/step - loss: 14.8291 - mean_squared_error: 14.8291 - mean_absolute_error: 2.5504 - acc: 0.1564\n",
      "\n",
      "Epoch 8/10\n",
      "39/39 [==============================]39/39 [==============================] - 71s 2s/step - loss: 14.3345 - mean_squared_error: 14.3345 - mean_absolute_error: 2.5083 - acc: 0.1462\n",
      "\n",
      "Epoch 9/10\n",
      "39/39 [==============================]39/39 [==============================] - 77s 2s/step - loss: 13.4340 - mean_squared_error: 13.4340 - mean_absolute_error: 2.3725 - acc: 0.1872\n",
      "\n",
      "Epoch 10/10\n",
      "39/39 [==============================]39/39 [==============================] - 77s 2s/step - loss: 13.2854 - mean_squared_error: 13.2854 - mean_absolute_error: 2.4094 - acc: 0.1667\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f259d8bfd0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (2,2), padding=\"same\",input_shape=(540, 960, 2), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'accuracy'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.4597096]\n",
      " [4.0453725]\n",
      " [2.5865219]\n",
      " [1.876172 ]\n",
      " [2.7817848]\n",
      " [4.3727183]\n",
      " [3.9000027]\n",
      " [2.5050535]\n",
      " [3.3840609]\n",
      " [3.5734978]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7]\n",
      " [5]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [9]\n",
      " [3]\n",
      " [2]\n",
      " [3]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2: Full Images - HSV\n",
    "This uses full size images that have people in them, converted to HSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================]39/39 [==============================] - 87s 2s/step - loss: 2378.7755 - mean_squared_error: 2378.7755 - mean_absolute_error: 24.0337 - acc: 0.0385\n",
      "\n",
      "Epoch 2/10\n",
      "39/39 [==============================]39/39 [==============================] - 83s 2s/step - loss: 15.1942 - mean_squared_error: 15.1942 - mean_absolute_error: 2.4477 - acc: 0.1872\n",
      "\n",
      "Epoch 3/10\n",
      "39/39 [==============================]39/39 [==============================] - 84s 2s/step - loss: 11.7206 - mean_squared_error: 11.7206 - mean_absolute_error: 2.2168 - acc: 0.1897\n",
      "\n",
      "Epoch 4/10\n",
      "39/39 [==============================]39/39 [==============================] - 86s 2s/step - loss: 10.5186 - mean_squared_error: 10.5186 - mean_absolute_error: 2.1461 - acc: 0.2333\n",
      "\n",
      "Epoch 5/10\n",
      "39/39 [==============================]39/39 [==============================] - 90s 2s/step - loss: 7.3852 - mean_squared_error: 7.3852 - mean_absolute_error: 1.7826 - acc: 0.2410\n",
      "\n",
      "Epoch 6/10\n",
      "39/39 [==============================]39/39 [==============================] - 82s 2s/step - loss: 5.5666 - mean_squared_error: 5.5666 - mean_absolute_error: 1.5621 - acc: 0.2718\n",
      "\n",
      "Epoch 7/10\n",
      "39/39 [==============================]39/39 [==============================] - 94s 2s/step - loss: 4.4254 - mean_squared_error: 4.4254 - mean_absolute_error: 1.4214 - acc: 0.2974\n",
      "\n",
      "Epoch 8/10\n",
      "39/39 [==============================]39/39 [==============================] - 83s 2s/step - loss: 3.8750 - mean_squared_error: 3.8750 - mean_absolute_error: 1.3513 - acc: 0.3051\n",
      "\n",
      "Epoch 9/10\n",
      "39/39 [==============================]39/39 [==============================] - 84s 2s/step - loss: 3.3686 - mean_squared_error: 3.3686 - mean_absolute_error: 1.2665 - acc: 0.2974\n",
      "\n",
      "Epoch 10/10\n",
      "39/39 [==============================]39/39 [==============================] - 86s 2s/step - loss: 4.5964 - mean_squared_error: 4.5964 - mean_absolute_error: 1.3662 - acc: 0.3333\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f25ad63fd0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (2,2), padding=\"same\",input_shape=(540, 960, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'accuracy'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0930457]\n",
      " [2.5246828]\n",
      " [1.4346604]\n",
      " [1.3098843]\n",
      " [1.7063771]\n",
      " [1.902762 ]\n",
      " [3.913823 ]\n",
      " [1.0183108]\n",
      " [1.3632728]\n",
      " [3.1236968]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7]\n",
      " [5]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [9]\n",
      " [3]\n",
      " [2]\n",
      " [3]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 3: Full Images - No Color Change\n",
    "This uses full size images that have people in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================]39/39 [==============================] - 85s 2s/step - loss: 1208.7269 - mean_squared_error: 1208.7269 - mean_absolute_error: 17.7038 - acc: 0.0231\n",
      "\n",
      "Epoch 2/10\n",
      "39/39 [==============================]39/39 [==============================] - 83s 2s/step - loss: 19.3600 - mean_squared_error: 19.3600 - mean_absolute_error: 3.0794 - acc: 0.1308\n",
      "\n",
      "Epoch 3/10\n",
      "39/39 [==============================]39/39 [==============================] - 80s 2s/step - loss: 14.3952 - mean_squared_error: 14.3952 - mean_absolute_error: 2.6225 - acc: 0.1462\n",
      "\n",
      "Epoch 4/10\n",
      "39/39 [==============================]39/39 [==============================] - 80s 2s/step - loss: 13.8770 - mean_squared_error: 13.8770 - mean_absolute_error: 2.4535 - acc: 0.1949\n",
      "\n",
      "Epoch 5/10\n",
      "39/39 [==============================]39/39 [==============================] - 81s 2s/step - loss: 11.1326 - mean_squared_error: 11.1326 - mean_absolute_error: 2.1599 - acc: 0.1923\n",
      "\n",
      "Epoch 6/10\n",
      "39/39 [==============================]39/39 [==============================] - 83s 2s/step - loss: 7.7102 - mean_squared_error: 7.7102 - mean_absolute_error: 1.9524 - acc: 0.2077\n",
      "\n",
      "Epoch 7/10\n",
      "39/39 [==============================]39/39 [==============================] - 81s 2s/step - loss: 6.7028 - mean_squared_error: 6.7028 - mean_absolute_error: 1.7195 - acc: 0.2436\n",
      "\n",
      "Epoch 8/10\n",
      "39/39 [==============================]39/39 [==============================] - 82s 2s/step - loss: 5.4880 - mean_squared_error: 5.4880 - mean_absolute_error: 1.6353 - acc: 0.2564\n",
      "\n",
      "Epoch 9/10\n",
      "39/39 [==============================]39/39 [==============================] - 83s 2s/step - loss: 5.0590 - mean_squared_error: 5.0590 - mean_absolute_error: 1.5240 - acc: 0.2923\n",
      "\n",
      "Epoch 10/10\n",
      "39/39 [==============================]39/39 [==============================] - 81s 2s/step - loss: 4.9470 - mean_squared_error: 4.9470 - mean_absolute_error: 1.4971 - acc: 0.3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f25c490240>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (2,2), padding=\"same\",input_shape=(540, 960, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'accuracy'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.3958495 ]\n",
      " [8.321123  ]\n",
      " [2.3532782 ]\n",
      " [1.035324  ]\n",
      " [0.70101446]\n",
      " [2.332126  ]\n",
      " [4.5625787 ]\n",
      " [0.87305564]\n",
      " [1.6255327 ]\n",
      " [2.5387604 ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7]\n",
      " [5]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [9]\n",
      " [3]\n",
      " [2]\n",
      " [3]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 4: Split Images - Grayscale\n",
    "This uses split images (from full images with people in them) that have been converted to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "976/976 [==============================]976/976 [==============================] - 309s 316ms/step - loss: 3.6022 - mean_squared_error: 3.6022 - mean_absolute_error: 0.4892 - acc: 0.8026\n",
      "\n",
      "Epoch 2/10\n",
      "976/976 [==============================]976/976 [==============================] - 105s 107ms/step - loss: 0.2864 - mean_squared_error: 0.2864 - mean_absolute_error: 0.2316 - acc: 0.8929\n",
      "\n",
      "Epoch 3/10\n",
      "976/976 [==============================]976/976 [==============================] - 113s 116ms/step - loss: 0.2791 - mean_squared_error: 0.2791 - mean_absolute_error: 0.2264 - acc: 0.8944\n",
      "\n",
      "Epoch 4/10\n",
      "976/976 [==============================]976/976 [==============================] - 105s 108ms/step - loss: 0.2707 - mean_squared_error: 0.2707 - mean_absolute_error: 0.2226 - acc: 0.8972\n",
      "\n",
      "Epoch 5/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 105ms/step - loss: 0.2707 - mean_squared_error: 0.2707 - mean_absolute_error: 0.2240 - acc: 0.8969\n",
      "\n",
      "Epoch 6/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 103ms/step - loss: 0.2708 - mean_squared_error: 0.2708 - mean_absolute_error: 0.2266 - acc: 0.8995\n",
      "\n",
      "Epoch 7/10\n",
      "976/976 [==============================]976/976 [==============================] - 100s 102ms/step - loss: 0.2708 - mean_squared_error: 0.2708 - mean_absolute_error: 0.2264 - acc: 0.8964\n",
      "\n",
      "Epoch 8/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 104ms/step - loss: 0.2647 - mean_squared_error: 0.2647 - mean_absolute_error: 0.2256 - acc: 0.9007\n",
      "\n",
      "Epoch 9/10\n",
      "976/976 [==============================]976/976 [==============================] - 100s 103ms/step - loss: 0.2709 - mean_squared_error: 0.2709 - mean_absolute_error: 0.2239 - acc: 0.8993\n",
      "\n",
      "Epoch 10/10\n",
      "976/976 [==============================]976/976 [==============================] - 99s 101ms/step - loss: 0.2824 - mean_squared_error: 0.2824 - mean_absolute_error: 0.2380 - acc: 0.8998\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f23f893128>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (2,2), padding=\"same\",input_shape=(108, 192, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'accuracy'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1062379 ]\n",
      " [0.12491779]\n",
      " [0.16854063]\n",
      " [0.10197994]\n",
      " [0.10313762]\n",
      " [0.11242331]\n",
      " [0.23321387]\n",
      " [0.10273636]\n",
      " [0.10166924]\n",
      " [0.10310157]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 5: Split Images - HSV\n",
    "This uses split images (from full images with people in them) that have been converted to hsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "976/976 [==============================]976/976 [==============================] - 109s 111ms/step - loss: 1.7533 - mean_squared_error: 1.7533 - mean_absolute_error: 0.4441 - acc: 0.8036\n",
      "\n",
      "Epoch 2/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 104ms/step - loss: 0.2722 - mean_squared_error: 0.2722 - mean_absolute_error: 0.2303 - acc: 0.8903\n",
      "\n",
      "Epoch 3/10\n",
      "976/976 [==============================]976/976 [==============================] - 103s 106ms/step - loss: 0.2588 - mean_squared_error: 0.2588 - mean_absolute_error: 0.2218 - acc: 0.8922\n",
      "\n",
      "Epoch 4/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 104ms/step - loss: 0.2462 - mean_squared_error: 0.2462 - mean_absolute_error: 0.2107 - acc: 0.8954\n",
      "\n",
      "Epoch 5/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 104ms/step - loss: 0.2452 - mean_squared_error: 0.2452 - mean_absolute_error: 0.2074 - acc: 0.8987\n",
      "\n",
      "Epoch 6/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 104ms/step - loss: 0.2380 - mean_squared_error: 0.2380 - mean_absolute_error: 0.2054 - acc: 0.9021\n",
      "\n",
      "Epoch 7/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 103ms/step - loss: 0.2276 - mean_squared_error: 0.2276 - mean_absolute_error: 0.1997 - acc: 0.9006\n",
      "\n",
      "Epoch 8/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 103ms/step - loss: 0.2288 - mean_squared_error: 0.2288 - mean_absolute_error: 0.1980 - acc: 0.9018\n",
      "\n",
      "Epoch 9/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 104ms/step - loss: 0.2232 - mean_squared_error: 0.2232 - mean_absolute_error: 0.1957 - acc: 0.9046\n",
      "\n",
      "Epoch 10/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 103ms/step - loss: 0.2200 - mean_squared_error: 0.2200 - mean_absolute_error: 0.1891 - acc: 0.9050\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f259090cf8>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (2,2), padding=\"same\",input_shape=(108, 192, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'accuracy'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0312355 ]\n",
      " [0.22261013]\n",
      " [0.09479196]\n",
      " [0.05141732]\n",
      " [0.05010214]\n",
      " [0.04356905]\n",
      " [0.19408457]\n",
      " [0.03841535]\n",
      " [0.06442752]\n",
      " [0.09745529]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 6: Split Images - No Color Change\n",
    "This uses split images (from full images with people in them). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 104ms/step - loss: 1.9541 - mean_squared_error: 1.9541 - mean_absolute_error: 0.4151 - acc: 0.8239\n",
      "\n",
      "Epoch 2/10\n",
      "976/976 [==============================]976/976 [==============================] - 97s 100ms/step - loss: 0.2725 - mean_squared_error: 0.2725 - mean_absolute_error: 0.2224 - acc: 0.8905\n",
      "\n",
      "Epoch 3/10\n",
      "976/976 [==============================]976/976 [==============================] - 105s 107ms/step - loss: 0.2613 - mean_squared_error: 0.2613 - mean_absolute_error: 0.2167 - acc: 0.8943\n",
      "\n",
      "Epoch 4/10\n",
      "976/976 [==============================]976/976 [==============================] - 104s 107ms/step - loss: 0.2624 - mean_squared_error: 0.2624 - mean_absolute_error: 0.2197 - acc: 0.8954\n",
      "\n",
      "Epoch 5/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 105ms/step - loss: 0.2544 - mean_squared_error: 0.2544 - mean_absolute_error: 0.2163 - acc: 0.8962\n",
      "\n",
      "Epoch 6/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 105ms/step - loss: 0.2494 - mean_squared_error: 0.2494 - mean_absolute_error: 0.2193 - acc: 0.8978\n",
      "\n",
      "Epoch 7/10\n",
      "976/976 [==============================]976/976 [==============================] - 103s 105ms/step - loss: 0.2523 - mean_squared_error: 0.2523 - mean_absolute_error: 0.2147 - acc: 0.8985\n",
      "\n",
      "Epoch 8/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 104ms/step - loss: 0.2659 - mean_squared_error: 0.2659 - mean_absolute_error: 0.2335 - acc: 0.8972\n",
      "\n",
      "Epoch 9/10\n",
      "976/976 [==============================]976/976 [==============================] - 102s 105ms/step - loss: 0.2607 - mean_squared_error: 0.2607 - mean_absolute_error: 0.2244 - acc: 0.9012\n",
      "\n",
      "Epoch 10/10\n",
      "976/976 [==============================]976/976 [==============================] - 101s 103ms/step - loss: 0.2926 - mean_squared_error: 0.2926 - mean_absolute_error: 0.2544 - acc: 0.9014\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1f25bac0eb8>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Set up Convolutional Network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, (2,2), padding=\"same\",input_shape=(108, 192, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(16, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'accuracy'])\n",
    "\n",
    "model.fit_generator(gather_images(train_X, train_Y, batch_size=batch_size),\n",
    "                    steps_per_epoch = len(train_X)//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13789415]\n",
      " [0.25354084]\n",
      " [0.13789415]\n",
      " [0.13789415]\n",
      " [0.13789415]\n",
      " [0.1382464 ]\n",
      " [0.19708386]\n",
      " [0.1383607 ]\n",
      " [0.13789415]\n",
      " [0.13789415]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(gather_images(test_X, test_Y, batch_size=batch_size), len(test_X)//batch_size)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "test_labels = next(gather_images(test_X, test_Y, batch_size=len(test_X)))[1]\n",
    "print(test_labels[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_notebook",
   "language": "python",
   "name": "tensor_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
